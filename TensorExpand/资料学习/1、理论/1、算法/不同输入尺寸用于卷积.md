# 1、通过pooling

深度网络需要固定输入尺寸的原因是因为有全链接层，不过在那个时候，还没有FCN的思想，那如何去做才能使得网络不受输入尺寸的限制呢？Kaiming He 大神就想出，用不同尺度的pooling 来pooling出固定尺度大小的feature map，这样就可以不受全链接层约束任意更改输入尺度了。下图就是SPP网络的核心思想： 
通过对feature map进行相应尺度的pooling，使得能pooling出4×4, 2×2, 1×1的feature map，再将这些feature map concat成列向量与下一层全链接层相连。这样就消除了输入尺度不一致的影响。训练的时候就用常规方法训练，不过由于不受尺度的影响，可以进行多尺度训练，即先resize成几个固定的尺度，然后用SPP网络进行训练，学习。

# 2、FCN
链接：[经典 CNNs 的 TensorFlow 实现资源汇总](https://www.jianshu.com/p/68cf89138dca)

可以接受任意大小的输入图像，而不用要求所有的训练图像和测试图像具有同样的尺寸


# 3、代码实现

```python
import tensorflow as tf
import numpy as np

img1=np.random.random([10,5,5,3]) # 0
img2=np.random.random([10,6,6,3]) # 1
img3=np.random.random([10,7,7,3]) # 2

# x=tf.placeholder(tf.float32,[10,None,None,3])
def conv_net(img):
    img=tf.convert_to_tensor(img,dtype=tf.float32)
    conv1=tf.layers.conv2d(img,32,3,padding='SAME',activation=tf.nn.relu)
    conv1=tf.layers.max_pooling2d(conv1,2,2,padding='SAME')

    h=conv1.shape[1]
    w=conv1.shape[2]

    # 1=(h+2*0-f)/1 +1 ==>f=h

    conv2=tf.layers.conv2d(conv1,3,[h,w])

    return conv2

print(conv_net(img1).get_shape)
print(conv_net(img2).get_shape)
print(conv_net(img3).get_shape)

'''
<bound method Tensor.get_shape of <tf.Tensor 'conv2d_2/BiasAdd:0' shape=(10, 1, 1, 3) dtype=float32>>
<bound method Tensor.get_shape of <tf.Tensor 'conv2d_4/BiasAdd:0' shape=(10, 1, 1, 3) dtype=float32>>
<bound method Tensor.get_shape of <tf.Tensor 'conv2d_6/BiasAdd:0' shape=(10, 1, 1, 3) dtype=float32>>
'''
```
