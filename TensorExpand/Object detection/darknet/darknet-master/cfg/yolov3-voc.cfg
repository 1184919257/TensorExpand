[net]
# Testing
 batch=1
 subdivisions=1
# Training
# batch=64
# subdivisions=16
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 50200
policy=steps
steps=40000,45000
scales=.1,.1


# [1,416,416,3]
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# Downsample
# [1,416,416,32]

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky
# [1,208,208,64]

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky
# [1,208,208,32]

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky
# [1,208,208,64]

[shortcut]
from=-3
activation=linear
# [1,208,208,64]
# Downsample

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky
# [1,104,104,128]

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky
# [1,104,104,64]

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
# [1,104,104,128]

[shortcut]
from=-3
activation=linear
# [1,104,104,128]

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky
# [1,104,104,64]

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
# [1,104,104,128]

[shortcut]
from=-3
activation=linear
# [1,104,104,128]
# Downsample

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky
# [1,52,52,256]


[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# [1,52,52,128]

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# [1,52,52,256]

[shortcut]
from=-3
activation=linear
# [1,52,52,256]

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# [1,52,52,128]

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# [1,52,52,256]

[shortcut]
from=-3
activation=linear
# [1,52,52,256]

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# [1,52,52,128]

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# [1,52,52,256]

[shortcut]
from=-3
activation=linear
# [1,52,52,256]

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# [1,52,52,128]

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# [1,52,52,256]
[shortcut]
from=-3
activation=linear
# [1,52,52,256]

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# [1,52,52,128]

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# [1,52,52,256]

[shortcut]
from=-3
activation=linear
# [1,52,52,256]

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# [1,52,52,128]

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# [1,52,52,256]

[shortcut]
from=-3
activation=linear
# [1,52,52,256]

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# [1,52,52,128]

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# [1,52,52,256]

[shortcut]
from=-3
activation=linear
# [1,52,52,256]

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# [1,52,52,128]

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# [1,52,52,256]

[shortcut]
from=-3
activation=linear
# [1,52,52,256]
# Downsample

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky
# [1,26,26,512]

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# [1,26,26,256]

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# [1,26,26,512]
[shortcut]
from=-3
activation=linear
# [1,26,26,512]

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# [1,26,26,256]

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# [1,26,26,512]

[shortcut]
from=-3
activation=linear
# [1,26,26,512]

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# [1,26,26,256]

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# [1,26,26,512]

[shortcut]
from=-3
activation=linear
# [1,26,26,512]

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# [1,26,26,256]

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# [1,26,26,512]

[shortcut]
from=-3
activation=linear
# [1,26,26,512]

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# [1,26,26,256]

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# [1,26,26,512]
[shortcut]
from=-3
activation=linear
# [1,26,26,512]

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# [1,26,26,256]

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# [1,26,26,512]
[shortcut]
from=-3
activation=linear
# [1,26,26,512]

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# [1,26,26,256]
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# [1,26,26,512]
[shortcut]
from=-3
activation=linear
# [1,26,26,512]
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# [1,26,26,256]
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# [1,26,26,512]
[shortcut]
from=-3
activation=linear
# [1,26,26,512]
# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky
# [1,13,13,1024]

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
# [1,13,13,512]
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
# [1,13,13,1024]
[shortcut]
from=-3
activation=linear
# [1,13,13,1024]
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
# [1,13,13,512]
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
# [1,13,13,1024]
[shortcut]
from=-3
activation=linear
# [1,13,13,1024]
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
# [1,13,13,512]
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
# [1,13,13,1024]
[shortcut]
from=-3
activation=linear
# [1,13,13,1024]
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
# [1,13,13,512]
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
# [1,13,13,1024]
[shortcut]
from=-3
activation=linear
# [1,13,13,1024]
######################

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
# [1,13,13,512]
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky
# [1,13,13,1024]
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
# [1,13,13,512]
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky
# [1,13,13,1024]
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
# [1,13,13,512]
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky
# [1,13,13,1024]
[convolutional]
size=1
stride=1
pad=1
filters=75
activation=linear
# [1,13,13,75]
[yolo]
mask = 6,7,8
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=20
num=9
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=1

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 61



[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=75
activation=linear

[yolo]
mask = 3,4,5
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=20
num=9
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=1

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 36



[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=75
activation=linear

[yolo]
mask = 0,1,2
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=20
num=9
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=1

